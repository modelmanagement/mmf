{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T13:46:34.065996Z",
     "start_time": "2019-03-25T13:46:33.834724Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext sparkmagic.magics\n",
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T10:10:49.414612Z",
     "start_time": "2019-04-01T10:10:49.398973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:21.553760Z",
     "start_time": "2019-03-25T15:01:21.524553Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:25.763182Z",
     "start_time": "2019-03-25T15:01:22.483658Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the joined parquet file \n",
    "df1 = spark.read.parquet(\"/Fannie-Mae/2016/FNMA_2016_Join_result_test.parquet/part*\")\n",
    "df2 = spark.read.parquet(\"/Fannie-Mae/2017/FNMA_2017_Join_result_test.parquet/part*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:31.728459Z",
     "start_time": "2019-03-25T15:01:31.486044Z"
    }
   },
   "outputs": [],
   "source": [
    "#Renaming the ForeclosureDate column of 2016 to Default\n",
    "df1 = df1.withColumnRenamed('ForeclosureDate','Default')\n",
    "#Renaming the ForeclosureDate column of 2017 to Default\n",
    "df2 = df2.withColumnRenamed('ForeclosureDate','Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:32.670937Z",
     "start_time": "2019-03-25T15:01:32.435397Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Default\",when(col(\"Default\").isNull(),0).otherwise(1))\n",
    "df2 = df2.withColumn(\"Default\",when(col(\"Default\").isNull(),0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:33.702238Z",
     "start_time": "2019-03-25T15:01:33.466893Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop('LoanID','Channel','SellerName','OrDate','FirstPayment','FTHomeBuyer','LoanPurpose','PropertyType','OccStatus','PropertyState','ProductType','RelMortInd','Servicer','MaturityDate','CurDelStatus','ModFlag','ZeroBalEffDate','LastInstallDate','DispositionDate','PricipleForgiven','RMWPF','FPWA','ServicingIndicator','OrLTV','Zip','MortInsPerc','CoCreditScore','MortInsType','CurrInterestRate','CAUPB','MSA','ForeclosureCost','RepairCost','AssetRecCost','MiscCostsPF','ATFHP','NetSaleProceeds','CreditEnhProceeds','RPMWP','OtherForePro','NonInterestUPB','ReportingDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:35.802526Z",
     "start_time": "2019-03-25T15:01:35.564038Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop('LoanID','Channel','SellerName','OrDate','FirstPayment','FTHomeBuyer','LoanPurpose','PropertyType','OccStatus','PropertyState','ProductType','RelMortInd','Servicer','MaturityDate','CurDelStatus','ModFlag','ZeroBalEffDate','LastInstallDate','DispositionDate','PricipleForgiven','RMWPF','FPWA','ServicingIndicator','OrLTV','Zip','MortInsPerc','CoCreditScore','MortInsType','CurrInterestRate','CAUPB','MSA','ForeclosureCost','RepairCost','AssetRecCost','MiscCostsPF','ATFHP','NetSaleProceeds','CreditEnhProceeds','RPMWP','OtherForePro','NonInterestUPB','ReportingDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:37.613920Z",
     "start_time": "2019-03-25T15:01:37.379697Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2016 = df1.na.fill(0)\n",
    "df_2017 = df2.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:40.441608Z",
     "start_time": "2019-03-25T15:01:39.179994Z"
    }
   },
   "outputs": [],
   "source": [
    "## Let's stratify the data since we have a small amount of Foreclosures\n",
    "positive_count_2016 = df_2016.filter(df_2016['Default'] == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:42.154725Z",
     "start_time": "2019-03-25T15:01:42.124336Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_count_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:46.571923Z",
     "start_time": "2019-03-25T15:01:44.308515Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_count_2017 = df_2017.filter(df_2017['Default'] == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:50.278401Z",
     "start_time": "2019-03-25T15:01:50.243164Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positive_count_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:56.784457Z",
     "start_time": "2019-03-25T15:01:56.039113Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size_2016 = df_2016.count()\n",
    "strat_data_2016 = df_2016.sampleBy('Default', fractions={0: float(positive_count_2016)/ data_size_2016, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:57.997590Z",
     "start_time": "2019-03-25T15:01:57.756565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strat_data_2016.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:02.901079Z",
     "start_time": "2019-03-25T15:01:59.620327Z"
    }
   },
   "outputs": [],
   "source": [
    "print(strat_data_2016.groupby('Default').count().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:06.367683Z",
     "start_time": "2019-03-25T15:02:04.106391Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size_2017 = df_2017.count()\n",
    "strat_data_2017 = df_2017.sampleBy('Default', fractions={0: float(positive_count_2017)/ data_size_2017, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:08.114722Z",
     "start_time": "2019-03-25T15:02:07.867983Z"
    }
   },
   "outputs": [],
   "source": [
    "strat_data_2017.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:14.874328Z",
     "start_time": "2019-03-25T15:02:09.588253Z"
    }
   },
   "outputs": [],
   "source": [
    "print(strat_data_2017.groupby('Default').count().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:17.479152Z",
     "start_time": "2019-03-25T15:02:17.451451Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = strat_data_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:19.012660Z",
     "start_time": "2019-03-25T15:02:18.986504Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = strat_data_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:20.582779Z",
     "start_time": "2019-03-25T15:02:20.556318Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:22.358710Z",
     "start_time": "2019-03-25T15:02:22.116175Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:24.082561Z",
     "start_time": "2019-03-25T15:02:23.842417Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_cols_2016 = df_2016.drop('Default').drop('id').columns\n",
    "assembler_2016 = VectorAssembler(inputCols=feature_cols_2016, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:25.719922Z",
     "start_time": "2019-03-25T15:02:25.483126Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol='Default', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:27.352259Z",
     "start_time": "2019-03-25T15:02:27.114558Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler_2016, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:28.332694Z",
     "start_time": "2019-03-25T15:02:28.306323Z"
    }
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [1, 10, 100]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:29.891597Z",
     "start_time": "2019-03-25T15:02:29.651657Z"
    }
   },
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol='Default', predictionCol='prediction'),\n",
    "                          numFolds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:41.166312Z",
     "start_time": "2019-03-25T15:02:31.251806Z"
    }
   },
   "outputs": [],
   "source": [
    "time_s = time()\n",
    "cv_model = crossval.fit(train_data)\n",
    "time_e = time()\n",
    "\n",
    "print ('Total training time: %f' % (time_e - time_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:47.011253Z",
     "start_time": "2019-03-25T15:03:46.981112Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print('Precision of True ', metrics.precision(1))\n",
    "    print('Precision of False', metrics.precision(0))\n",
    "    print('Recall of True    ', metrics.recall(1))\n",
    "    print('Recall of False   ', metrics.recall(0))\n",
    "    print('F-1 Score         ', metrics.fMeasure())\n",
    "    print('Confusion Matrix\\n', metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:50.087823Z",
     "start_time": "2019-03-25T15:03:49.852291Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:56.449592Z",
     "start_time": "2019-03-25T15:03:54.172912Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = cv_model.transform(test_data)\n",
    "accuracy = cv_model.getEvaluator().evaluate(predictions)\n",
    "print('F1 Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:06.843938Z",
     "start_time": "2019-03-25T15:04:06.606642Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_and_labels = predictions.select(\"prediction\", \"Default\").rdd.map(lambda r: (float(r[0]), float(r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:21.600499Z",
     "start_time": "2019-03-25T15:04:16.205886Z"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
