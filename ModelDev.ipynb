{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/Fannie-Mae/2015Q1/Acquisition_2015Q1.txt\")\n",
    "\n",
    "df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldColumns = df.schema.names\n",
    "col_acq = ['LoanID','Channel','SellerName','OrInterestRate','OrUnpaidPrinc','OrLoanTerm',\n",
    "        'OrDate','FirstPayment','OrLTV','OrCLTV','NumBorrow','DTIRat','CreditScore',\n",
    "        'FTHomeBuyer','LoanPurpose','PropertyType','NumUnits','OccStatus','PropertyState',\n",
    "        'Zip','MortInsPerc','ProductType','CoCreditScore','MortInsType','RelMortInd'];\n",
    "\n",
    "aquisitionDF = reduce(lambda df, idx: df.withColumnRenamed(oldColumns[idx], col_acq[idx]), xrange(len(oldColumns)), df)\n",
    "aquisitionDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read\\\n",
    "    .format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/Fannie-Mae/2015Q1/Performance_2015Q1.txt\")\n",
    "oldColumns2 = df2.schema.names\n",
    "col_per = ['LoanID','ReportingDate','Servicer','CurrInterestRate','CAUPB','LoanAge','MonthsToMaturity',\n",
    "          'AdMonthsToMaturity','MaturityDate','MSA','CurDelStatus','ModFlag','ZeroBalCode','ZeroBalEffDate',\n",
    "          'LastInstallDate','ForeclosureDate','DispositionDate','ForeclosureCost','RepairCost','AssetRecCost','MiscCostsPF',\n",
    "          'ATFHP','NetSaleProceeds','CreditEnhProceeds','RPMWP','OtherForePro','NonInterestUPB','PricipleForgiven','RMWPF',\n",
    "          'FPWA','ServicingIndicator'];\n",
    "performanceDF = reduce(lambda df2, idx: df2.withColumnRenamed(oldColumns2[idx], col_per[idx]), xrange(len(oldColumns2)), df2)\n",
    "performanceDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import io\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
